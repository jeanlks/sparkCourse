{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/home/jean/spark-2.4.4-bin-hadoop2.7\")\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('logisticregression').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_df = spark.createDataFrame([\n",
    "    (0, \"Hi I am testing spark\"),\n",
    "    (1, \"Python is better than Java for machine learning\"),\n",
    "    (2, \"Logistic,regression,testing\")\n",
    "], [\"id\", \"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|            sentence|\n",
      "+---+--------------------+\n",
      "|  0|Hi I am testing s...|\n",
      "|  1|Python is better ...|\n",
      "|  2|Logistic,regressi...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "send_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_tokenizer = RegexTokenizer(inputCol=\"sentence\", outputCol=\"words\", pattern=\"\\\\W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tokens = udf(lambda words:len(words), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.transform(send_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+------+\n",
      "| id|            sentence|               words|tokens|\n",
      "+---+--------------------+--------------------+------+\n",
      "|  0|Hi I am testing s...|[hi, i, am, testi...|     5|\n",
      "|  1|Python is better ...|[python, is, bett...|     8|\n",
      "|  2|Logistic,regressi...|[logistic,regress...|     1|\n",
      "+---+--------------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized.withColumn(\"tokens\", count_tokens(col('words'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_tokenized = regex_tokenizer.transform(send_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+------+\n",
      "| id|            sentence|               words|tokens|\n",
      "+---+--------------------+--------------------+------+\n",
      "|  0|Hi I am testing s...|[hi, i, am, testi...|     5|\n",
      "|  1|Python is better ...|[python, is, bett...|     8|\n",
      "|  2|Logistic,regressi...|[logistic, regres...|     3|\n",
      "+---+--------------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rg_tokenized.withColumn(\"tokens\", count_tokens(col('words'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+\n",
      "| id|            sentence|               words|             removed|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "|  0|Hi I am testing s...|[hi, i, am, testi...|[hi, testing, spark]|\n",
      "|  1|Python is better ...|[python, is, bett...|[python, better, ...|\n",
      "|  2|Logistic,regressi...|[logistic, regres...|[logistic, regres...|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover.transform(rg_tokenized).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = NGram(n=2, inputCol=\"removed\", outputCol=\"ngram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------+------------------------------------------------------------+\n",
      "|words                                                   |ngram                                                       |\n",
      "+--------------------------------------------------------+------------------------------------------------------------+\n",
      "|[hi, i, am, testing, spark]                             |[hi testing, testing spark]                                 |\n",
      "|[python, is, better, than, java, for, machine, learning]|[python better, better java, java machine, machine learning]|\n",
      "|[logistic, regression, testing]                         |[logistic regression, regression testing]                   |\n",
      "+--------------------------------------------------------+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram.transform(remover.transform(rg_tokenized)).select([\"words\", \"ngram\"]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|            sentence|               words|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|Hi I am testing s...|[hi, i, am, testi...|\n",
      "|  1|Python is better ...|[python, is, bett...|\n",
      "|  2|Logistic,regressi...|[logistic, regres...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rg_tokenized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing_tf = HashingTF(inputCol=\"words\", outputCol=\"raw_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized_data = hashing_tf.transform(rg_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+\n",
      "| id|            sentence|               words|        raw_features|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "|  0|Hi I am testing s...|[hi, i, am, testi...|(262144,[24417,49...|\n",
      "|  1|Python is better ...|[python, is, bett...|(262144,[1836,158...|\n",
      "|  2|Logistic,regressi...|[logistic, regres...|(262144,[13671,76...|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_model = idf.fit(featurized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_data = idf_model.transform(featurized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|            sentence|               words|        raw_features|            features|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0|Hi I am testing s...|[hi, i, am, testi...|(262144,[24417,49...|(262144,[24417,49...|\n",
      "|  1|Python is better ...|[python, is, bett...|(262144,[1836,158...|(262144,[1836,158...|\n",
      "|  2|Logistic,regressi...|[logistic, regres...|(262144,[13671,76...|(262144,[13671,76...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaled_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
